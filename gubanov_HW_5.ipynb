{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Условия\n",
    "Дано 2 csv-файла: один с текстом — articles.csv, второй со стоп-словами — stopwords.csv.\n",
    "\n",
    "Необходимо в Jupyter-ноутбуке выполнить следующие пункты, используя SQLite или Pandas совместно с Python (очистку данных можно проводить также либо с помощью Python, либо используя SQL или Pandas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 1\n",
    "Прочитать файлы и создать над ними таблицы, где структуры таблиц:\n",
    "\n",
    "### 1. articles в виде:\n",
    "\n",
    " |-- id: integer (nullable = true)\n",
    " |-- text: string (nullable = true)\n",
    "\n",
    "### 2. stopwords в виде:\n",
    "\n",
    " |-- word: string (nullable = true)\n",
    "До выполнения задачи изначально обработать данные:\n",
    "\n",
    "при парсинге отбросить все символы, которые не являются латинскими буквами;\n",
    "привести все слова к нижнему регистру;\n",
    "удалить все стоп-слова из articles с помощью таблицы stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sqlite3 as sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Читаем файлы и создаем таблицы с помощью pandas\n",
    "articles = pd.read_csv(\"articles.csv\", delimiter=';', names=[\"text\"], header=None)\n",
    "stopwords = pd.read_csv(\"stopwords.csv\", delimiter=';', names=[\"word\"], header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производим отчистку текста "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для отчистки текста \n",
    "def clean_text(text):\n",
    "    # Формируем маску с использованием регулятрного выражения, \n",
    "    # чтобы оставить только латинские буквы\n",
    "    cleaned_text = re.sub('[^a-zA-Z\\s]', '', text)\n",
    "    # Привести текст к нижнему регистру\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Очистка текста статей\n",
    "articles['text'] = articles['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем множество стоп-слов\n",
    "stopwords_set = set(stopwords['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем  стоп-слова из текста\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stopwords_set]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "\n",
    "articles['text'] = articles['text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление столбца ID\n",
    "articles.insert(0, 'id', np.arange(1, len(articles) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создание соединения с базой данных SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sql.connect('articles.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "733"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаем таблицы articles и stopwords\n",
    "articles.to_sql('articles', conn, if_exists='replace', index=False)\n",
    "\n",
    "stopwords.to_sql('stopwords', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим данные в таблице "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bradley charles cooper born january american a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>cooper enrolled mfa program actors studio begi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>cooper found greater success romantic comedy s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>labeled sex symbol media cooper named people m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>cooper born january abington township near phi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text\n",
       "0   1  bradley charles cooper born january american a...\n",
       "1   2  cooper enrolled mfa program actors studio begi...\n",
       "2   3  cooper found greater success romantic comedy s...\n",
       "3   4  labeled sex symbol media cooper named people m...\n",
       "4   5  cooper born january abington township near phi..."
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_from_db = pd.read_sql_query(\"SELECT * FROM articles\", conn)\n",
    "articles_from_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 2\n",
    "Извлечь коллокации в тексте articles.csv. Это комбинации слов, которые часто встречаются вместе. Например, «smart boss» или «linings playbook». Чтобы найти совпадения, нужно использовать метрику NPMI (нормализованная точечная взаимная информация).\n",
    "\n",
    "PMI двух слов a и b определяется как:\n",
    "\n",
    "PMI(a,b) = ln(P(a,b)/(P(a)*P(b)))\n",
    "\n",
    "где P(a,b) — вероятность двух слов, идущих подряд, а P(a) и  P(b)  — вероятности слов a и b соответственно.\n",
    "Вам нужно будет оценить вероятности встречаемости слов, то есть  P(a)  — это вероятность появления слова a, которая считается как отношение количества повторений слова a на общее количество слов, P(ab) — вероятность появления комбинации ab относительно всех пар, которая считается как отношение количества повторений пары ab на общее количество пар.\n",
    "NPMI вычисляется как:\n",
    "\n",
    "NPMI(a,b) = -( PMI(a,b)/lnP(a,b))\n",
    "\n",
    "Это нормализует величину в диапазон [-1; 1].\n",
    "Таким образом, для каждой комбинации слов ab посчитать NPMI и вывести на экран TOP-50 самых популярных коллокаций, отсортированных по убыванию значения NPMI.\n",
    "Комбинацию слов ab объединить пробелом.\n",
    "\n",
    "Пример вывода\n",
    "\n",
    "|smart boss             |1.0044481503489615|\n",
    "\n",
    "|smart home             |1.0041328218065497|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cоздаем функцию для вычисления NPMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npmi(p_a, p_b, p_ab):\n",
    "    pmi = log(p_ab / (p_a * p_b))\n",
    "    return -pmi / log(p_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считаем слова и пары\n",
    "word_count = Counter()\n",
    "pair_count = Counter()\n",
    "total_words = 0\n",
    "total_pairs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x12b23edc0>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sql.connect('articles.db')\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT text FROM articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in cur.fetchall():\n",
    "    words = row[0].split()\n",
    "    total_words += len(words)\n",
    "    total_pairs += len(words) - 1\n",
    "    word_count.update(words)\n",
    "    pair_count.update(zip(words[:-1], words[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисляем вероятность для слов и пар слов\n",
    "word_probs = {word: count / total_words for word, count in word_count.items()}\n",
    "pair_probs = {pair: count / total_pairs for pair, count in pair_count.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисляем NPMI для каждой пары слов\n",
    "npmi_values = {pair: npmi(word_probs[pair[0]], word_probs[pair[1]], pair_prob) for pair, pair_prob in pair_probs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем таблицу NPMI \n",
    "npmi_table = pd.DataFrame([(pair[0], pair[1], npmi) for pair, npmi in npmi_values.items()], columns=['word_a', 'word_b', 'npmi'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сортируем значения и оставляем ТОП 50\n",
    "top_50_npmi = npmi_table.sort_values(by='npmi', ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "# изменяем представление \n",
    "\n",
    "top_50_npmi['words'] = top_50_npmi.apply(lambda row: row[0] + ' ' + row[1], axis=1)\n",
    "top_50_npmi = top_50_npmi.drop(['word_a', 'word_b'], axis=1)\n",
    "table = PrettyTable(['Words', 'NPMI'])\n",
    "for row in top_50_npmi.itertuples(index=False):\n",
    "    words = row[1]\n",
    "    npmi = row[0]\n",
    "    table.add_row([words, npmi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+--------------------+\n",
      "|               Words                |        NPMI        |\n",
      "+------------------------------------+--------------------+\n",
      "|              fish fry              | 1.0052239644191399 |\n",
      "|          nightmare alley           | 1.0051069538755188 |\n",
      "|          linings playbook          | 1.0051069538755188 |\n",
      "|            los angeles             | 1.0051069538755188 |\n",
      "|          guardians galaxy          | 1.0049706878472697 |\n",
      "|            willy wanker            | 1.004805384273404  |\n",
      "|         iberian peninsula          | 1.004805384273404  |\n",
      "|           licorice pizza           | 1.004805384273404  |\n",
      "|            barack obama            | 1.004805384273404  |\n",
      "|          ella fitzgerald           | 1.0045902343009177 |\n",
      "|         severely deformed          | 1.0045902343009177 |\n",
      "|           clint eastwood           | 1.0045902343009177 |\n",
      "|             angkor wat             | 1.0045902343009177 |\n",
      "|           milvian bridge           | 1.0045902343009177 |\n",
      "|       individuals hazardous        | 1.0045902343009177 |\n",
      "|         apostolicae sedis          | 1.0045902343009177 |\n",
      "|           foot minstrels           | 1.0045902343009177 |\n",
      "|          bipolar disorder          | 1.0045902343009177 |\n",
      "|           carries heavy            | 1.0045902343009177 |\n",
      "|            rabbit foot             | 1.0045902343009177 |\n",
      "|            steven moll             | 1.0045902343009177 |\n",
      "|        hazardous equipment         | 1.0045902343009177 |\n",
      "|           allison rader            | 1.0045902343009177 |\n",
      "|            parke custis            | 1.0045902343009177 |\n",
      "|          elderly neighbor          | 1.0045902343009177 |\n",
      "|            amos bronson            | 1.0045902343009177 |\n",
      "|             pulls gun              | 1.0045902343009177 |\n",
      "|           harold stassen           | 1.0045902343009177 |\n",
      "|           joel whitburns           | 1.0045902343009177 |\n",
      "|          herbal medicines          | 1.0045902343009177 |\n",
      "|       unskilled individuals        | 1.0045902343009177 |\n",
      "|            bing crosby             | 1.0045902343009177 |\n",
      "|        equipment unsanitary        | 1.0045902343009177 |\n",
      "|            phil wenneck            | 1.0045902343009177 |\n",
      "|            irina shayk             | 1.0045902343009177 |\n",
      "|           here chickens            | 1.0045902343009177 |\n",
      "|             pounds kg              | 1.0045902343009177 |\n",
      "|          elks rendezvous           | 1.0045902343009177 |\n",
      "|          parthenon frieze          | 1.004263879456239  |\n",
      "|            milt gabler             | 1.004263879456239  |\n",
      "|      coveney whatsonstagecom       | 1.004263879456239  |\n",
      "|          teenager resists          | 1.004263879456239  |\n",
      "|            avoids trap             | 1.004263879456239  |\n",
      "|           ambitus templi           | 1.004263879456239  |\n",
      "|         fears prosecution          | 1.004263879456239  |\n",
      "|          furets massively          | 1.004263879456239  |\n",
      "|         essay interpreting         | 1.004263879456239  |\n",
      "| antiestablishment environmentalist | 1.004263879456239  |\n",
      "|             dirty eats             | 1.004263879456239  |\n",
      "|            eats garbage            | 1.004263879456239  |\n",
      "+------------------------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# Выводим резлультат\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
